
Correct

In a lake, there is a patch of lily pads. Every day, the patch doubles in size. If it takes 48 days for the
patch to cover the entire lake, how long would it take for the patch to cover half of the lake?

24

47

If it takes 5 machines 5 minutes to make 5 widgets, how many minutes would it take 100 machines
to make 100 widgets?

100

5

A bat & a ball cost $1.10 in total. The bat costs $1.00 more than the ball. How much does the ball cost?

10 c

5c

Each subject answered 5 trials for each of the 3 questions. In the first trial, subjects responded independently. In the subsequent trials 2 to 5, subjects could see the responses that their network neighbors
entered in previous rounds. No information was given about the accuracy of these responses. Subjects
were informed that they would accumulate monetary rewards for every correct response they gave, on
every trial. This setup provides an ideal test-bed to pit analytical process contagion against analytical
output contagion. Output contagion should improve performance from one trial to the next (within
each question), but not from one question to the next. Process contagion should improve performance
from one question to the next, in addition to improving performance from one trial to the next.
2.

RESULTS

Subjects’ performance appears in the figure below. Separate logistic regressions were conducted in each
topology. To detect process contagion, we tested whether the performance of subjects in each of our four
topologies improved across questions, over and above the progression observed in the baseline condition. For example, in the case of the Clustered topology, we conducted a logistic regression in which the
predictors were the question (first, second, third), the topology (Baseline, Clustered), and their interaction. The dependent measure was the performance (correct or incorrect) during the first trial of each
question. What counts as evidence for process contagion is a significant interaction between question
and topology, showing that increase in performance in the network group is greater than increase in
performance in the Baseline group. We detected no such significant interaction for any topology, all
z < 1.05, all p > .28. Performance never improves significantly from one question to the next.
To detect output contagion, we tested whether the performance of subjects in each of our four topologies improved across trials within each question, above the progression observed in the Baseline. For
example, in the case of the Clustered topology, we conducted a logistic regression in which the predictors were the trial (first, last), the topology (Baseline, Clustered), and their interaction. What counts
as evidence for process contagion is a significant interaction between trial and topology, showing that
increase in performance in the network group is greater than in the Baseline group. We obtained
such evidence for all topologies except Clustered. In all other topologies, subjects’ performance largely
improved across trials, as the correct response to each question spread in turn across the network.
The Clustered topology was an exception insofar as it seemed unable to improve performance over
the Baseline group. One possible reason might be that connectivity in the Clustered network is insufficient to spread the correct, analytical response. To test whether the individual connectivity of a node
was linked to the final performance of the subject in this node, we computed an index of connectivity
(global distance to all other nodes, i.e., closeness centrality) and an index of final performance (average
proportion of correct responses during the last trial of each question), for each node in each network.
As expected, they were significantly correlated, r(78) = .38, p < .0001.
3.

DISCUSSION

Our data show that networks can help to solve analytic problems – but with a caveat. Networks do
not propagate the analytic reasoning style required to independently arrive at correct answers. They
Collective Intelligence 2014.

Analytical reasoning task reveals limits of social learning in networks

TOPOLOGY

Full

Erdos−Renyi

First Question

Barabasi−Albert

Clustered

Second Question

•

1:3

Baseline

Third Question

Proportion of correct responses

1.00

0.75

0.50

0.25

0.00
1

2

3

4

5

1

2

3

4

5

1

2

3

4

5

Trial

can only propagate the correct response to analytic problems, one at a time. This failure to propagate
analytical processing is striking. Consider that it is possible to prime analytical processing using very
subtle cues—such as an evocative image of Rodin’s Thinker [Gervais and Norenzayan 2012] or listing
questions using a challenging font [Alter et al. 2007]. How can we explain, then, that repeated exposure
to the analytic output of peers in a network, and even the subsequent recognition and adoption of their
correct answer, all fail to prime analytic reasoning in subsequent tasks?
Social learning is a low-cost phenomenon because learners evaluate behaviors without necessarily
understanding what makes a behavior successful. The trade-off, though, is that without that deep understanding, learners can be inaccurate in what they choose to copy [Boyd et al. 2011]. This propensity
may explain why subjects persist in copying only analytical responses in our tasks, whilst copying analytical processing would be fairly easy, cost-less, and financially rewarding. We have therefore identified an unreflective copying bias, thus contributing to our understanding of the limits of increased
connectivity in amplifying collective intelligence [Sparrow et al. 2011; Lorenz et al. 2011].
REFERENCES
A. L. Alter, D. M. Oppenheimer, N. Epley, and R. N. Eyre. 2007. Overcoming intuition: metacognitive difficulty activates analytic
reasoning. Journal of Experimental Psychology: General 136, 4 (2007), 569.
R. Boyd, P. J. Richerson, and J. Henrich. 2011. The cultural niche: Why social learning is essential for human adaptation. PNAS
108, Supplement 2 (2011), 10918–10925.
D. Centola. 2010. The spread of behavior in an online social network experiment. Science 329, 5996 (2010), 1194–1197.
J. H. Fowler and N. A. Christakis. 2010. Cooperative behavior cascades in human social networks. PNAS 107, 12 (2010).
S. Frederick. 2005. Cognitive reflection and decision making. Journal of Economic Perspectives 19, 4 (2005), 25–42.
W. M. Gervais and A. Norenzayan. 2012. Analytic thinking promotes religious disbelief. Science 336, 6080 (2012), 493–496.
D. Kahneman. 2011. Thinking, fast and slow. Farrar, Straus and Giroux, New York.
J. Lorenz, H. Rauhut, F. Schweitzer, and D. Helbing. 2011. How social influence can undermine the wisdom of crowd effect.
PNAS 108, 22 (2011), 9020–9025.
W. Mason and D. J. Watts. 2012. Collaborative learning in networks. PNAS 109, 3 (2012), 764–769.
A. Pentland. 2012. The new science of building great teams. Harvard Business Review 90, 4 (2012), 60–69.
L. Rendell, R. Boyd, D. Cownden, M. Enquist, K. Eriksson, M. W. Feldman, L. Fogarty, S. Ghirlanda, T. Lillicrap, and K. N.
Laland. 2010. Why copy others? Insights from the social learning strategies tournament. Science 328, 5975 (2010), 208–213.
B. Sparrow, J. Liu, and D. M. Wegner. 2011. Google effects on memory: Cognitive consequences of having information at our
fingertips. Science 333, 6043 (2011), 776–778.
Collective Intelligence 2014.

